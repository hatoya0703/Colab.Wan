{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wan2.2 Video Generation on Google Colab\n",
    "\n",
    "Wan2.2をGoogle Colabで動かすためのノートブック\n",
    "\n",
    "## 特徴\n",
    "- GPU自動検出と最適化設定\n",
    "- ComfyUI版と公式CLI版の両方に対応\n",
    "- T4 (15GB) / A100 (40GB) 対応\n",
    "- メモリ最適化オプション\n",
    "\n",
    "## 対応モデル\n",
    "| モデル | タイプ | VRAM | T4対応 |\n",
    "|--------|--------|------|--------|\n",
    "| TI2V-5B | テキスト＆画像→動画 | 8GB | OK |\n",
    "| I2V-14B | 画像→動画 | 24GB+ | 要量子化 |\n",
    "| T2V-14B | テキスト→動画 | 24GB+ | 要量子化 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. 環境確認とGPU検出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Dec 29 16:06:07 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   42C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "\n",
      "==================================================\n",
      "GPU: Tesla T4\n",
      "VRAM: 14.7 GB\n",
      "推奨モデル: 5B\n",
      "推奨解像度: 832x480\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import torch\n",
    "\n",
    "def get_gpu_info():\n",
    "    \"\"\"GPU情報を取得して最適な設定を返す\"\"\"\n",
    "    if not torch.cuda.is_available():\n",
    "        return None, 0, {}\n",
    "    \n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
    "    \n",
    "    # GPU別の推奨設定\n",
    "    if \"A100\" in gpu_name:\n",
    "        config = {\n",
    "            \"recommended_model\": \"14B\",\n",
    "            \"max_resolution\": \"1280x720\",\n",
    "            \"offload_model\": False,\n",
    "            \"t5_cpu\": False,\n",
    "            \"use_fp8\": True\n",
    "        }\n",
    "    elif \"T4\" in gpu_name or gpu_memory < 20:\n",
    "        config = {\n",
    "            \"recommended_model\": \"5B\",\n",
    "            \"max_resolution\": \"832x480\",\n",
    "            \"offload_model\": True,\n",
    "            \"t5_cpu\": True,\n",
    "            \"use_fp8\": True\n",
    "        }\n",
    "    else:\n",
    "        config = {\n",
    "            \"recommended_model\": \"14B\",\n",
    "            \"max_resolution\": \"1280x720\",\n",
    "            \"offload_model\": True,\n",
    "            \"t5_cpu\": False,\n",
    "            \"use_fp8\": True\n",
    "        }\n",
    "    \n",
    "    return gpu_name, gpu_memory, config\n",
    "\n",
    "# GPU情報を表示\n",
    "!nvidia-smi\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "gpu_name, gpu_memory, gpu_config = get_gpu_info()\n",
    "print(f\"GPU: {gpu_name}\")\n",
    "print(f\"VRAM: {gpu_memory:.1f} GB\")\n",
    "print(f\"推奨モデル: {gpu_config.get('recommended_model', 'N/A')}\")\n",
    "print(f\"推奨解像度: {gpu_config.get('max_resolution', 'N/A')}\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. 設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 設定パネル { display-mode: \"form\" }\n",
    "\n",
    "#@markdown ### 実行モード\n",
    "EXECUTION_MODE = \"comfyui\" #@param [\"comfyui\", \"cli\"]\n",
    "\n",
    "#@markdown ### モデル選択\n",
    "MODEL_TYPE = \"TI2V-5B\" #@param [\"TI2V-5B\", \"I2V-14B\", \"T2V-14B\"]\n",
    "\n",
    "#@markdown ### 解像度\n",
    "RESOLUTION = \"832x480\" #@param [\"1280x720\", \"832x480\", \"480x832\", \"1024x1024\"]\n",
    "\n",
    "#@markdown ### メモリ最適化（T4では全てON推奨）\n",
    "OFFLOAD_MODEL = True #@param {type:\"boolean\"}\n",
    "T5_ON_CPU = True #@param {type:\"boolean\"}\n",
    "CONVERT_DTYPE = True #@param {type:\"boolean\"}\n",
    "\n",
    "#@markdown ### Google Drive連携\n",
    "USE_GOOGLE_DRIVE = False #@param {type:\"boolean\"}\n",
    "DRIVE_OUTPUT_DIR = \"/content/drive/MyDrive/Wan2.2_outputs\" #@param {type:\"string\"}\n",
    "\n",
    "#@markdown ### トンネル設定（ComfyUIモード用）\n",
    "NGROK_TOKEN = \"\" #@param {type:\"string\"}\n",
    "\n",
    "# 設定の表示\n",
    "print(\"=== 現在の設定 ===\")\n",
    "print(f\"実行モード: {EXECUTION_MODE}\")\n",
    "print(f\"モデル: {MODEL_TYPE}\")\n",
    "print(f\"解像度: {RESOLUTION}\")\n",
    "print(f\"メモリ最適化: offload={OFFLOAD_MODEL}, t5_cpu={T5_ON_CPU}, convert={CONVERT_DTYPE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Google Drive連携（オプション）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if USE_GOOGLE_DRIVE:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    os.makedirs(DRIVE_OUTPUT_DIR, exist_ok=True)\n",
    "    print(f\"Google Drive connected. Output: {DRIVE_OUTPUT_DIR}\")\n",
    "else:\n",
    "    print(\"Google Drive: 未使用\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. インストール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import os\n",
    "\n",
    "if EXECUTION_MODE == \"comfyui\":\n",
    "    # ComfyUIのインストール\n",
    "    if not os.path.exists(\"/content/ComfyUI\"):\n",
    "        !git clone https://github.com/comfyanonymous/ComfyUI.git /content/ComfyUI\n",
    "    %cd /content/ComfyUI\n",
    "    !pip install -q -r requirements.txt\n",
    "    !pip install -q huggingface_hub\n",
    "    print(\"ComfyUI installed.\")\n",
    "else:\n",
    "    # 公式Wan2.2のインストール\n",
    "    if not os.path.exists(\"/content/Wan2.2\"):\n",
    "        !git clone https://github.com/Wan-Video/Wan2.2.git /content/Wan2.2\n",
    "    %cd /content/Wan2.2\n",
    "    !pip install -q -r requirements.txt\n",
    "    !pip install -q .\n",
    "    !pip install -q huggingface_hub\n",
    "    print(\"Wan2.2 CLI installed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. モデルダウンロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from huggingface_hub import hf_hub_download, snapshot_download\n",
    "import os\n",
    "\n",
    "if EXECUTION_MODE == \"comfyui\":\n",
    "    # ComfyUI用モデルディレクトリ\n",
    "    os.makedirs(\"models/diffusion_models\", exist_ok=True)\n",
    "    os.makedirs(\"models/clip\", exist_ok=True)\n",
    "    os.makedirs(\"models/vae\", exist_ok=True)\n",
    "    \n",
    "    print(f\"Downloading {MODEL_TYPE} for ComfyUI...\")\n",
    "    \n",
    "    # Diffusion Model\n",
    "    if MODEL_TYPE == \"TI2V-5B\":\n",
    "        hf_hub_download(\n",
    "            repo_id=\"Comfy-Org/Wan_2.2_ComfyUI_repackaged\",\n",
    "            filename=\"split_files/diffusion_models/wan2.2_ti2v_5B_fp16.safetensors\",\n",
    "            local_dir=\"models\"\n",
    "        )\n",
    "    elif MODEL_TYPE == \"I2V-14B\":\n",
    "        hf_hub_download(\n",
    "            repo_id=\"Comfy-Org/Wan_2.2_ComfyUI_repackaged\",\n",
    "            filename=\"split_files/diffusion_models/wan2.2_i2v_A14B_fp16_high_noise.safetensors\",\n",
    "            local_dir=\"models\"\n",
    "        )\n",
    "        hf_hub_download(\n",
    "            repo_id=\"Comfy-Org/Wan_2.2_ComfyUI_repackaged\",\n",
    "            filename=\"split_files/diffusion_models/wan2.2_i2v_A14B_fp16_low_noise.safetensors\",\n",
    "            local_dir=\"models\"\n",
    "        )\n",
    "    elif MODEL_TYPE == \"T2V-14B\":\n",
    "        hf_hub_download(\n",
    "            repo_id=\"Comfy-Org/Wan_2.2_ComfyUI_repackaged\",\n",
    "            filename=\"split_files/diffusion_models/wan2.2_t2v_A14B_fp16.safetensors\",\n",
    "            local_dir=\"models\"\n",
    "        )\n",
    "    \n",
    "    # Text Encoder\n",
    "    hf_hub_download(\n",
    "        repo_id=\"Comfy-Org/Wan_2.2_ComfyUI_repackaged\",\n",
    "        filename=\"split_files/text_encoders/umt5_xxl_fp8_e4m3fn_scaled.safetensors\",\n",
    "        local_dir=\"models\"\n",
    "    )\n",
    "    \n",
    "    # VAE\n",
    "    hf_hub_download(\n",
    "        repo_id=\"Comfy-Org/Wan_2.2_ComfyUI_repackaged\",\n",
    "        filename=\"split_files/vae/wan_2.2_vae.safetensors\",\n",
    "        local_dir=\"models\"\n",
    "    )\n",
    "    \n",
    "    # ファイルを正しい場所に移動\n",
    "    !mv models/split_files/diffusion_models/* models/diffusion_models/ 2>/dev/null || true\n",
    "    !mv models/split_files/text_encoders/* models/clip/ 2>/dev/null || true\n",
    "    !mv models/split_files/vae/* models/vae/ 2>/dev/null || true\n",
    "    !rm -rf models/split_files 2>/dev/null || true\n",
    "    \n",
    "else:\n",
    "    # 公式CLI用モデル\n",
    "    print(f\"Downloading {MODEL_TYPE} for CLI...\")\n",
    "    \n",
    "    if MODEL_TYPE == \"TI2V-5B\":\n",
    "        repo_id = \"Wan-AI/Wan2.2-TI2V-5B\"\n",
    "    elif MODEL_TYPE == \"I2V-14B\":\n",
    "        repo_id = \"Wan-AI/Wan2.2-I2V-A14B\"\n",
    "    elif MODEL_TYPE == \"T2V-14B\":\n",
    "        repo_id = \"Wan-AI/Wan2.2-T2V-A14B\"\n",
    "    \n",
    "    model_dir = f\"./models/{MODEL_TYPE}\"\n",
    "    !huggingface-cli download {repo_id} --local-dir {model_dir}\n",
    "\n",
    "print(\"\\nModel download complete!\")\n",
    "!ls -la models/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6A. ComfyUIモードで実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXECUTION_MODE == \"comfyui\":\n",
    "    # ngrokトンネル設定\n",
    "    if NGROK_TOKEN:\n",
    "        !pip install -q pyngrok\n",
    "        from pyngrok import ngrok\n",
    "        ngrok.set_auth_token(NGROK_TOKEN)\n",
    "        public_url = ngrok.connect(8188)\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"ComfyUI URL: {public_url}\")\n",
    "        print(f\"{'='*50}\\n\")\n",
    "    else:\n",
    "        print(\"ngrok未設定。localhostのみアクセス可能。\")\n",
    "        print(\"Colabの場合、出力ポートからアクセスしてください。\")\n",
    "    \n",
    "    # ComfyUI起動\n",
    "    !python main.py --listen 0.0.0.0 --port 8188\n",
    "else:\n",
    "    print(\"CLIモードが選択されています。次のセルに進んでください。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6B. CLIモードで実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 動画生成設定 { display-mode: \"form\" }\n",
    "\n",
    "if EXECUTION_MODE == \"cli\":\n",
    "    #@markdown ### 入力画像（I2Vモード用）\n",
    "    INPUT_IMAGE = \"/content/input.jpg\" #@param {type:\"string\"}\n",
    "    \n",
    "    #@markdown ### プロンプト\n",
    "    PROMPT = \"A beautiful sunset over the ocean, waves gently rolling, cinematic quality\" #@param {type:\"string\"}\n",
    "    \n",
    "    #@markdown ### フレーム数\n",
    "    NUM_FRAMES = 49 #@param {type:\"slider\", min:17, max:121, step:4}\n",
    "    \n",
    "    print(\"設定完了。次のセルで動画生成を実行します。\")\n",
    "else:\n",
    "    print(\"ComfyUIモードが選択されています。6Aセルを実行してください。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXECUTION_MODE == \"cli\":\n",
    "    import torch\n",
    "    import os\n",
    "    \n",
    "    # VRAMクリア\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # タスク設定\n",
    "    if MODEL_TYPE == \"TI2V-5B\":\n",
    "        task = \"ti2v-5B\"\n",
    "        ckpt_dir = \"./models/TI2V-5B\"\n",
    "    elif MODEL_TYPE == \"I2V-14B\":\n",
    "        task = \"i2v-A14B\"\n",
    "        ckpt_dir = \"./models/I2V-14B\"\n",
    "    elif MODEL_TYPE == \"T2V-14B\":\n",
    "        task = \"t2v-A14B\"\n",
    "        ckpt_dir = \"./models/T2V-14B\"\n",
    "    \n",
    "    # 解像度パース\n",
    "    width, height = RESOLUTION.split(\"x\")\n",
    "    \n",
    "    # 最適化オプション構築\n",
    "    args = []\n",
    "    if OFFLOAD_MODEL:\n",
    "        args.append(\"--offload_model True\")\n",
    "    if T5_ON_CPU:\n",
    "        args.append(\"--t5_cpu\")\n",
    "    if CONVERT_DTYPE:\n",
    "        args.append(\"--convert_model_dtype\")\n",
    "    \n",
    "    args_str = \" \".join(args)\n",
    "    \n",
    "    # 出力ディレクトリ\n",
    "    output_dir = DRIVE_OUTPUT_DIR if USE_GOOGLE_DRIVE else \"./outputs\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # 実行コマンド構築\n",
    "    cmd = f\"\"\"python generate.py \\\n",
    "        --task {task} \\\n",
    "        --size {width}*{height} \\\n",
    "        --ckpt_dir {ckpt_dir} \\\n",
    "        --prompt \"{PROMPT}\" \\\n",
    "        --frame_num {NUM_FRAMES} \\\n",
    "        --save_path {output_dir} \\\n",
    "        {args_str}\"\"\"\n",
    "    \n",
    "    # 画像入力がある場合\n",
    "    if \"i2v\" in task.lower() or \"ti2v\" in task.lower():\n",
    "        if os.path.exists(INPUT_IMAGE):\n",
    "            cmd += f' --image \"{INPUT_IMAGE}\"'\n",
    "    \n",
    "    print(\"実行コマンド:\")\n",
    "    print(cmd)\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"動画生成を開始します...\")\n",
    "    print(\"=\"*50 + \"\\n\")\n",
    "    \n",
    "    !{cmd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成された動画を表示\n",
    "if EXECUTION_MODE == \"cli\":\n",
    "    import glob\n",
    "    from IPython.display import Video, display\n",
    "    \n",
    "    output_dir = DRIVE_OUTPUT_DIR if USE_GOOGLE_DRIVE else \"./outputs\"\n",
    "    videos = sorted(glob.glob(f\"{output_dir}/*.mp4\"), key=os.path.getmtime, reverse=True)\n",
    "    \n",
    "    if videos:\n",
    "        latest_video = videos[0]\n",
    "        print(f\"最新の動画: {latest_video}\")\n",
    "        display(Video(latest_video, embed=True, width=640))\n",
    "    else:\n",
    "        print(\"動画が見つかりません。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. 画像アップロード（I2V用）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "from IPython.display import Image, display\n",
    "import shutil\n",
    "\n",
    "print(\"画像をアップロードしてください...\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "if uploaded:\n",
    "    for filename in uploaded.keys():\n",
    "        # 入力画像として保存\n",
    "        shutil.copy(filename, \"/content/input.jpg\")\n",
    "        print(f\"\\n{filename} を /content/input.jpg として保存しました\")\n",
    "        display(Image(filename, width=400))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Tips\n",
    "\n",
    "### T4 GPU (15GB) での推奨設定\n",
    "- モデル: TI2V-5B\n",
    "- 解像度: 832x480\n",
    "- 全メモリ最適化オプションON\n",
    "\n",
    "### A100 GPU (40GB) での推奨設定\n",
    "- モデル: I2V-14B または T2V-14B\n",
    "- 解像度: 1280x720\n",
    "- メモリ最適化は必要に応じて\n",
    "\n",
    "### 生成時間目安\n",
    "- T4 + 5B: 15-25分/動画\n",
    "- A100 + 14B: 5-10分/動画\n",
    "\n",
    "### トラブルシューティング\n",
    "- OOMエラー: 解像度を下げる、メモリ最適化オプションをONに\n",
    "- セッション切断: Google Drive連携で出力を保存"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
